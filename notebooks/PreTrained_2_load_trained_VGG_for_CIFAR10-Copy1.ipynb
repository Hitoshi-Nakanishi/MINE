{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, itertools\n",
    "from pathlib import Path\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#from PreTrainedFIM.model import VGG16_FIM, VGG16bn_FIM\n",
    "from PreTrainedFIM.repara_model import VGG16bn_FIM\n",
    "from PreTrainedFIM.util import CIFAR10Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'epoch_num': 10,\n",
    "          'log_interval': 1250}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "vgg_model = VGG16bn_FIM().to(device)\n",
    "vgg_model = vgg_model.to_device_child_tensors(device)\n",
    "vgg_model.eval_FIM()\n",
    "\n",
    "#filename = '1epoch_VGG16bn_p1_w0_jnb.pth'\n",
    "#worker = worker.set_save_path(filename).load_chckpt()\n",
    "\n",
    "optimizer = optim.Adam(vgg_model.parameters(), lr=0.1)\n",
    "worker = CIFAR10Worker(device, vgg_model, _, params)\n",
    "worker = worker.load_data_loader()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for epoch in range(0,1):\n",
    "    worker.evaluate_FIM(epoch, optimizer)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#worker.model.features[1].logvar.requires_grad\n",
    "worker.model.features[1].logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0158, 0.0158, 0.0158, 0.0158, 0.0158, 0.0158, 0.0158, 0.0158, 0.0158,\n",
       "        0.0158, 0.0158, 0.0158, 0.0158], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker.model.logvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker.model.features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(76069.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000], device='cuda:0', requires_grad=True)\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 9508.659180\n",
      "loss tensor(2.2764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([5.6618e-09, 5.6618e-09, 5.6618e-09, 5.6618e-09, 5.6618e-09, 5.6618e-09,\n",
      "        5.6618e-09, 5.6618e-09, 5.6618e-09, 5.6618e-09, 5.6618e-09, 5.6618e-09,\n",
      "        5.6618e-09], device='cuda:0', requires_grad=True)\n",
      "loss tensor(32300.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0670, -0.0670, -0.0670, -0.0670, -0.0670, -0.0670, -0.0670, -0.0670,\n",
      "        -0.0670, -0.0670, -0.0670, -0.0670, -0.0670], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(43116.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0776, -0.0776, -0.0776, -0.0776, -0.0776, -0.0776, -0.0776, -0.0776,\n",
      "        -0.0776, -0.0776, -0.0776, -0.0776, -0.0776], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(21745.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0549, -0.0549, -0.0549, -0.0549, -0.0549, -0.0549, -0.0549, -0.0549,\n",
      "        -0.0549, -0.0549, -0.0549, -0.0549, -0.0549], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(2355.6450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0179, -0.0179, -0.0179, -0.0179, -0.0179, -0.0179, -0.0179, -0.0179,\n",
      "        -0.0179, -0.0179, -0.0179, -0.0179, -0.0179], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(2867.7097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197,\n",
      "        0.0197, 0.0197, 0.0197, 0.0197], device='cuda:0', requires_grad=True)\n",
      "loss tensor(15672.6436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.0458, 0.0458, 0.0458, 0.0458, 0.0458, 0.0458, 0.0458, 0.0458, 0.0458,\n",
      "        0.0458, 0.0458, 0.0458, 0.0458], device='cuda:0', requires_grad=True)\n",
      "loss tensor(21494.7168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.0536, 0.0536, 0.0536, 0.0536, 0.0536, 0.0536, 0.0536, 0.0536, 0.0536,\n",
      "        0.0536, 0.0536, 0.0536, 0.0536], device='cuda:0', requires_grad=True)\n",
      "loss tensor(14745.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.0444, 0.0444, 0.0444, 0.0444, 0.0444, 0.0444, 0.0444, 0.0444, 0.0444,\n",
      "        0.0444, 0.0444, 0.0444, 0.0444], device='cuda:0', requires_grad=True)\n",
      "loss tensor(4326.7393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.0242, 0.0242, 0.0242, 0.0242, 0.0242, 0.0242, 0.0242, 0.0242, 0.0242,\n",
      "        0.0242, 0.0242, 0.0242, 0.0242], device='cuda:0', requires_grad=True)\n",
      "loss tensor(4.0306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004,\n",
      "        -0.0004, -0.0004, -0.0004, -0.0004, -0.0004], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(3676.1143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0224, -0.0224, -0.0224, -0.0224, -0.0224, -0.0224, -0.0224, -0.0224,\n",
      "        -0.0224, -0.0224, -0.0224, -0.0224, -0.0224], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(9513.9463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0362, -0.0362, -0.0362, -0.0362, -0.0362, -0.0362, -0.0362, -0.0362,\n",
      "        -0.0362, -0.0362, -0.0362, -0.0362, -0.0362], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(11048.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0390, -0.0390, -0.0390, -0.0390, -0.0390, -0.0390, -0.0390, -0.0390,\n",
      "        -0.0390, -0.0390, -0.0390, -0.0390, -0.0390], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(7264.0835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0316, -0.0316, -0.0316, -0.0316, -0.0316, -0.0316, -0.0316, -0.0316,\n",
      "        -0.0316, -0.0316, -0.0316, -0.0316, -0.0316], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(2103.1963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0170, -0.0170, -0.0170, -0.0170, -0.0170, -0.0170, -0.0170, -0.0170,\n",
      "        -0.0170, -0.0170, -0.0170, -0.0170, -0.0170], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(4.0765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
      "        0.0006, 0.0006, 0.0006, 0.0006], device='cuda:0', requires_grad=True)\n",
      "loss tensor(1994.3916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164,\n",
      "        0.0164, 0.0164, 0.0164, 0.0164], device='cuda:0', requires_grad=True)\n",
      "loss tensor(5164.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.0264, 0.0264, 0.0264, 0.0264, 0.0264, 0.0264, 0.0264, 0.0264, 0.0264,\n",
      "        0.0264, 0.0264, 0.0264, 0.0264], device='cuda:0', requires_grad=True)\n",
      "loss tensor(5959.3740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.0283, 0.0283, 0.0283, 0.0283, 0.0283, 0.0283, 0.0283, 0.0283, 0.0283,\n",
      "        0.0283, 0.0283, 0.0283, 0.0283], device='cuda:0', requires_grad=True)\n",
      "loss tensor(3763.8521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.0225, 0.0225, 0.0225, 0.0225, 0.0225, 0.0225, 0.0225, 0.0225, 0.0225,\n",
      "        0.0225, 0.0225, 0.0225, 0.0225], device='cuda:0', requires_grad=True)\n",
      "loss tensor(942.2295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.0113, 0.0113, 0.0113, 0.0113, 0.0113, 0.0113, 0.0113, 0.0113, 0.0113,\n",
      "        0.0113, 0.0113, 0.0113, 0.0113], device='cuda:0', requires_grad=True)\n",
      "loss tensor(30.3079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020,\n",
      "        -0.0020, -0.0020, -0.0020, -0.0020, -0.0020], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(1336.8236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0135, -0.0135, -0.0135, -0.0135, -0.0135, -0.0135, -0.0135, -0.0135,\n",
      "        -0.0135, -0.0135, -0.0135, -0.0135, -0.0135], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(3022.0361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0203, -0.0203, -0.0203, -0.0203, -0.0203, -0.0203, -0.0203, -0.0203,\n",
      "        -0.0203, -0.0203, -0.0203, -0.0203, -0.0203], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(3225.4695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0210, -0.0210, -0.0210, -0.0210, -0.0210, -0.0210, -0.0210, -0.0210,\n",
      "        -0.0210, -0.0210, -0.0210, -0.0210, -0.0210], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(1845.3771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0159, -0.0159, -0.0159, -0.0159, -0.0159, -0.0159, -0.0159, -0.0159,\n",
      "        -0.0159, -0.0159, -0.0159, -0.0159, -0.0159], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(344.2884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.0068, -0.0068, -0.0068, -0.0068, -0.0068, -0.0068, -0.0068, -0.0068,\n",
      "        -0.0068, -0.0068, -0.0068, -0.0068, -0.0068], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "loss tensor(84.7105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
      "        0.0033, 0.0033, 0.0033, 0.0033], device='cuda:0', requires_grad=True)\n",
      "loss tensor(1000.1723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([0.0116, 0.0116, 0.0116, 0.0116, 0.0116, 0.0116, 0.0116, 0.0116, 0.0116,\n",
      "        0.0116, 0.0116, 0.0116, 0.0116], device='cuda:0', requires_grad=True)\n",
      "====> Epoch: 0 Average loss: 5.9405\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for param in vgg_model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([4096, 25088])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([10, 4096])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in optimizer.param_groups[0]['params']:\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8283e-23, device='cuda:0')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['params'][2].grad"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for param in optimizer.param_groups[0]['params']:\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "optimizer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "None\n",
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 1321337.625000\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.9692e+03, 6.3343e+04, 1.2669e+05, 2.5337e+05, 5.0674e+05, 1.0135e+06,\n",
      "        1.0135e+06, 2.0270e+06, 4.0539e+06, 4.0539e+06, 4.0539e+06, 4.0539e+06,\n",
      "        4.0539e+06], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([5.9384e+03, 1.2669e+05, 2.5337e+05, 5.0674e+05, 1.0135e+06, 2.0270e+06,\n",
      "        2.0270e+06, 4.0539e+06, 8.1079e+06, 8.1079e+06, 8.1079e+06, 8.1079e+06,\n",
      "        8.1079e+06], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([8.9076e+03, 1.9003e+05, 3.8006e+05, 7.6011e+05, 1.5202e+06, 3.0405e+06,\n",
      "        3.0405e+06, 6.0809e+06, 1.2162e+07, 1.2162e+07, 1.2162e+07, 1.2162e+07,\n",
      "        1.2162e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.1877e+04, 2.5337e+05, 5.0674e+05, 1.0135e+06, 2.0270e+06, 4.0539e+06,\n",
      "        4.0539e+06, 8.1079e+06, 1.6216e+07, 1.6216e+07, 1.6216e+07, 1.6216e+07,\n",
      "        1.6216e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.4846e+04, 3.1671e+05, 6.3343e+05, 1.2669e+06, 2.5337e+06, 5.0674e+06,\n",
      "        5.0674e+06, 1.0135e+07, 2.0270e+07, 2.0270e+07, 2.0270e+07, 2.0270e+07,\n",
      "        2.0270e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.7815e+04, 3.8006e+05, 7.6011e+05, 1.5202e+06, 3.0405e+06, 6.0809e+06,\n",
      "        6.0809e+06, 1.2162e+07, 2.4324e+07, 2.4324e+07, 2.4324e+07, 2.4324e+07,\n",
      "        2.4324e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.0784e+04, 4.4340e+05, 8.8680e+05, 1.7736e+06, 3.5472e+06, 7.0944e+06,\n",
      "        7.0944e+06, 1.4189e+07, 2.8378e+07, 2.8378e+07, 2.8378e+07, 2.8378e+07,\n",
      "        2.8378e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.3754e+04, 5.0674e+05, 1.0135e+06, 2.0270e+06, 4.0539e+06, 8.1079e+06,\n",
      "        8.1079e+06, 1.6216e+07, 3.2431e+07, 3.2431e+07, 3.2431e+07, 3.2431e+07,\n",
      "        3.2431e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.6723e+04, 5.7008e+05, 1.1402e+06, 2.2803e+06, 4.5607e+06, 9.1214e+06,\n",
      "        9.1214e+06, 1.8243e+07, 3.6485e+07, 3.6485e+07, 3.6485e+07, 3.6485e+07,\n",
      "        3.6485e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.9692e+04, 6.3343e+05, 1.2669e+06, 2.5337e+06, 5.0674e+06, 1.0135e+07,\n",
      "        1.0135e+07, 2.0270e+07, 4.0539e+07, 4.0539e+07, 4.0539e+07, 4.0539e+07,\n",
      "        4.0539e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([3.2661e+04, 6.9677e+05, 1.3935e+06, 2.7871e+06, 5.5742e+06, 1.1148e+07,\n",
      "        1.1148e+07, 2.2297e+07, 4.4593e+07, 4.4593e+07, 4.4593e+07, 4.4593e+07,\n",
      "        4.4593e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([3.5630e+04, 7.6011e+05, 1.5202e+06, 3.0405e+06, 6.0809e+06, 1.2162e+07,\n",
      "        1.2162e+07, 2.4324e+07, 4.8647e+07, 4.8647e+07, 4.8647e+07, 4.8647e+07,\n",
      "        4.8647e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([3.8599e+04, 8.2346e+05, 1.6469e+06, 3.2938e+06, 6.5876e+06, 1.3175e+07,\n",
      "        1.3175e+07, 2.6351e+07, 5.2701e+07, 5.2701e+07, 5.2701e+07, 5.2701e+07,\n",
      "        5.2701e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([4.1569e+04, 8.8680e+05, 1.7736e+06, 3.5472e+06, 7.0944e+06, 1.4189e+07,\n",
      "        1.4189e+07, 2.8378e+07, 5.6755e+07, 5.6755e+07, 5.6755e+07, 5.6755e+07,\n",
      "        5.6755e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([4.4538e+04, 9.5014e+05, 1.9003e+06, 3.8006e+06, 7.6011e+06, 1.5202e+07,\n",
      "        1.5202e+07, 3.0405e+07, 6.0809e+07, 6.0809e+07, 6.0809e+07, 6.0809e+07,\n",
      "        6.0809e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([4.7507e+04, 1.0135e+06, 2.0270e+06, 4.0539e+06, 8.1079e+06, 1.6216e+07,\n",
      "        1.6216e+07, 3.2431e+07, 6.4863e+07, 6.4863e+07, 6.4863e+07, 6.4863e+07,\n",
      "        6.4863e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([5.0476e+04, 1.0768e+06, 2.1537e+06, 4.3073e+06, 8.6146e+06, 1.7229e+07,\n",
      "        1.7229e+07, 3.4458e+07, 6.8917e+07, 6.8917e+07, 6.8917e+07, 6.8917e+07,\n",
      "        6.8917e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([5.3445e+04, 1.1402e+06, 2.2803e+06, 4.5607e+06, 9.1214e+06, 1.8243e+07,\n",
      "        1.8243e+07, 3.6485e+07, 7.2971e+07, 7.2971e+07, 7.2971e+07, 7.2971e+07,\n",
      "        7.2971e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([5.6415e+04, 1.2035e+06, 2.4070e+06, 4.8140e+06, 9.6281e+06, 1.9256e+07,\n",
      "        1.9256e+07, 3.8512e+07, 7.7025e+07, 7.7025e+07, 7.7025e+07, 7.7025e+07,\n",
      "        7.7025e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([5.9384e+04, 1.2669e+06, 2.5337e+06, 5.0674e+06, 1.0135e+07, 2.0270e+07,\n",
      "        2.0270e+07, 4.0539e+07, 8.1079e+07, 8.1079e+07, 8.1079e+07, 8.1079e+07,\n",
      "        8.1079e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([6.2353e+04, 1.3302e+06, 2.6604e+06, 5.3208e+06, 1.0642e+07, 2.1283e+07,\n",
      "        2.1283e+07, 4.2566e+07, 8.5133e+07, 8.5133e+07, 8.5133e+07, 8.5133e+07,\n",
      "        8.5133e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([6.5322e+04, 1.3935e+06, 2.7871e+06, 5.5742e+06, 1.1148e+07, 2.2297e+07,\n",
      "        2.2297e+07, 4.4593e+07, 8.9187e+07, 8.9187e+07, 8.9187e+07, 8.9187e+07,\n",
      "        8.9187e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([6.8291e+04, 1.4569e+06, 2.9138e+06, 5.8275e+06, 1.1655e+07, 2.3310e+07,\n",
      "        2.3310e+07, 4.6620e+07, 9.3241e+07, 9.3241e+07, 9.3241e+07, 9.3241e+07,\n",
      "        9.3241e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([7.1261e+04, 1.5202e+06, 3.0405e+06, 6.0809e+06, 1.2162e+07, 2.4324e+07,\n",
      "        2.4324e+07, 4.8647e+07, 9.7294e+07, 9.7294e+07, 9.7294e+07, 9.7294e+07,\n",
      "        9.7294e+07], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([7.4230e+04, 1.5836e+06, 3.1671e+06, 6.3343e+06, 1.2669e+07, 2.5337e+07,\n",
      "        2.5337e+07, 5.0674e+07, 1.0135e+08, 1.0135e+08, 1.0135e+08, 1.0135e+08,\n",
      "        1.0135e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([7.7199e+04, 1.6469e+06, 3.2938e+06, 6.5876e+06, 1.3175e+07, 2.6351e+07,\n",
      "        2.6351e+07, 5.2701e+07, 1.0540e+08, 1.0540e+08, 1.0540e+08, 1.0540e+08,\n",
      "        1.0540e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([8.0168e+04, 1.7103e+06, 3.4205e+06, 6.8410e+06, 1.3682e+07, 2.7364e+07,\n",
      "        2.7364e+07, 5.4728e+07, 1.0946e+08, 1.0946e+08, 1.0946e+08, 1.0946e+08,\n",
      "        1.0946e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([8.3137e+04, 1.7736e+06, 3.5472e+06, 7.0944e+06, 1.4189e+07, 2.8378e+07,\n",
      "        2.8378e+07, 5.6755e+07, 1.1351e+08, 1.1351e+08, 1.1351e+08, 1.1351e+08,\n",
      "        1.1351e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([8.6107e+04, 1.8369e+06, 3.6739e+06, 7.3478e+06, 1.4696e+07, 2.9391e+07,\n",
      "        2.9391e+07, 5.8782e+07, 1.1756e+08, 1.1756e+08, 1.1756e+08, 1.1756e+08,\n",
      "        1.1756e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([8.9076e+04, 1.9003e+06, 3.8006e+06, 7.6011e+06, 1.5202e+07, 3.0405e+07,\n",
      "        3.0405e+07, 6.0809e+07, 1.2162e+08, 1.2162e+08, 1.2162e+08, 1.2162e+08,\n",
      "        1.2162e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([9.2045e+04, 1.9636e+06, 3.9273e+06, 7.8545e+06, 1.5709e+07, 3.1418e+07,\n",
      "        3.1418e+07, 6.2836e+07, 1.2567e+08, 1.2567e+08, 1.2567e+08, 1.2567e+08,\n",
      "        1.2567e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([9.5014e+04, 2.0270e+06, 4.0539e+06, 8.1079e+06, 1.6216e+07, 3.2431e+07,\n",
      "        3.2431e+07, 6.4863e+07, 1.2973e+08, 1.2973e+08, 1.2973e+08, 1.2973e+08,\n",
      "        1.2973e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([9.7983e+04, 2.0903e+06, 4.1806e+06, 8.3612e+06, 1.6722e+07, 3.3445e+07,\n",
      "        3.3445e+07, 6.6890e+07, 1.3378e+08, 1.3378e+08, 1.3378e+08, 1.3378e+08,\n",
      "        1.3378e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.0095e+05, 2.1537e+06, 4.3073e+06, 8.6146e+06, 1.7229e+07, 3.4458e+07,\n",
      "        3.4458e+07, 6.8917e+07, 1.3783e+08, 1.3783e+08, 1.3783e+08, 1.3783e+08,\n",
      "        1.3783e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.0392e+05, 2.2170e+06, 4.4340e+06, 8.8680e+06, 1.7736e+07, 3.5472e+07,\n",
      "        3.5472e+07, 7.0944e+07, 1.4189e+08, 1.4189e+08, 1.4189e+08, 1.4189e+08,\n",
      "        1.4189e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.0689e+05, 2.2803e+06, 4.5607e+06, 9.1214e+06, 1.8243e+07, 3.6485e+07,\n",
      "        3.6485e+07, 7.2971e+07, 1.4594e+08, 1.4594e+08, 1.4594e+08, 1.4594e+08,\n",
      "        1.4594e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.0986e+05, 2.3437e+06, 4.6874e+06, 9.3747e+06, 1.8749e+07, 3.7499e+07,\n",
      "        3.7499e+07, 7.4998e+07, 1.5000e+08, 1.5000e+08, 1.5000e+08, 1.5000e+08,\n",
      "        1.5000e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.1283e+05, 2.4070e+06, 4.8140e+06, 9.6281e+06, 1.9256e+07, 3.8512e+07,\n",
      "        3.8512e+07, 7.7025e+07, 1.5405e+08, 1.5405e+08, 1.5405e+08, 1.5405e+08,\n",
      "        1.5405e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.1580e+05, 2.4704e+06, 4.9407e+06, 9.8815e+06, 1.9763e+07, 3.9526e+07,\n",
      "        3.9526e+07, 7.9052e+07, 1.5810e+08, 1.5810e+08, 1.5810e+08, 1.5810e+08,\n",
      "        1.5810e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.1877e+05, 2.5337e+06, 5.0674e+06, 1.0135e+07, 2.0270e+07, 4.0539e+07,\n",
      "        4.0539e+07, 8.1079e+07, 1.6216e+08, 1.6216e+08, 1.6216e+08, 1.6216e+08,\n",
      "        1.6216e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.2174e+05, 2.5971e+06, 5.1941e+06, 1.0388e+07, 2.0776e+07, 4.1553e+07,\n",
      "        4.1553e+07, 8.3106e+07, 1.6621e+08, 1.6621e+08, 1.6621e+08, 1.6621e+08,\n",
      "        1.6621e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.2471e+05, 2.6604e+06, 5.3208e+06, 1.0642e+07, 2.1283e+07, 4.2566e+07,\n",
      "        4.2566e+07, 8.5133e+07, 1.7027e+08, 1.7027e+08, 1.7027e+08, 1.7027e+08,\n",
      "        1.7027e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.2768e+05, 2.7237e+06, 5.4475e+06, 1.0895e+07, 2.1790e+07, 4.3580e+07,\n",
      "        4.3580e+07, 8.7160e+07, 1.7432e+08, 1.7432e+08, 1.7432e+08, 1.7432e+08,\n",
      "        1.7432e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.3064e+05, 2.7871e+06, 5.5742e+06, 1.1148e+07, 2.2297e+07, 4.4593e+07,\n",
      "        4.4593e+07, 8.9187e+07, 1.7837e+08, 1.7837e+08, 1.7837e+08, 1.7837e+08,\n",
      "        1.7837e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.3361e+05, 2.8504e+06, 5.7008e+06, 1.1402e+07, 2.2803e+07, 4.5607e+07,\n",
      "        4.5607e+07, 9.1214e+07, 1.8243e+08, 1.8243e+08, 1.8243e+08, 1.8243e+08,\n",
      "        1.8243e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.3658e+05, 2.9138e+06, 5.8275e+06, 1.1655e+07, 2.3310e+07, 4.6620e+07,\n",
      "        4.6620e+07, 9.3241e+07, 1.8648e+08, 1.8648e+08, 1.8648e+08, 1.8648e+08,\n",
      "        1.8648e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.3955e+05, 2.9771e+06, 5.9542e+06, 1.1908e+07, 2.3817e+07, 4.7634e+07,\n",
      "        4.7634e+07, 9.5267e+07, 1.9053e+08, 1.9053e+08, 1.9053e+08, 1.9053e+08,\n",
      "        1.9053e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.4252e+05, 3.0405e+06, 6.0809e+06, 1.2162e+07, 2.4324e+07, 4.8647e+07,\n",
      "        4.8647e+07, 9.7294e+07, 1.9459e+08, 1.9459e+08, 1.9459e+08, 1.9459e+08,\n",
      "        1.9459e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.4549e+05, 3.1038e+06, 6.2076e+06, 1.2415e+07, 2.4830e+07, 4.9661e+07,\n",
      "        4.9661e+07, 9.9321e+07, 1.9864e+08, 1.9864e+08, 1.9864e+08, 1.9864e+08,\n",
      "        1.9864e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.4846e+05, 3.1671e+06, 6.3343e+06, 1.2669e+07, 2.5337e+07, 5.0674e+07,\n",
      "        5.0674e+07, 1.0135e+08, 2.0270e+08, 2.0270e+08, 2.0270e+08, 2.0270e+08,\n",
      "        2.0270e+08], device='cuda:0')\n",
      "Train Epoch: 0 [400/50000 (1%)]\tLoss: 1321337.625000\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.5143e+05, 3.2305e+06, 6.4610e+06, 1.2922e+07, 2.5844e+07, 5.1688e+07,\n",
      "        5.1688e+07, 1.0338e+08, 2.0675e+08, 2.0675e+08, 2.0675e+08, 2.0675e+08,\n",
      "        2.0675e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.5440e+05, 3.2938e+06, 6.5876e+06, 1.3175e+07, 2.6351e+07, 5.2701e+07,\n",
      "        5.2701e+07, 1.0540e+08, 2.1080e+08, 2.1080e+08, 2.1080e+08, 2.1080e+08,\n",
      "        2.1080e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.5737e+05, 3.3572e+06, 6.7143e+06, 1.3429e+07, 2.6857e+07, 5.3715e+07,\n",
      "        5.3715e+07, 1.0743e+08, 2.1486e+08, 2.1486e+08, 2.1486e+08, 2.1486e+08,\n",
      "        2.1486e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.6034e+05, 3.4205e+06, 6.8410e+06, 1.3682e+07, 2.7364e+07, 5.4728e+07,\n",
      "        5.4728e+07, 1.0946e+08, 2.1891e+08, 2.1891e+08, 2.1891e+08, 2.1891e+08,\n",
      "        2.1891e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.6331e+05, 3.4839e+06, 6.9677e+06, 1.3935e+07, 2.7871e+07, 5.5742e+07,\n",
      "        5.5742e+07, 1.1148e+08, 2.2297e+08, 2.2297e+08, 2.2297e+08, 2.2297e+08,\n",
      "        2.2297e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.6627e+05, 3.5472e+06, 7.0944e+06, 1.4189e+07, 2.8378e+07, 5.6755e+07,\n",
      "        5.6755e+07, 1.1351e+08, 2.2702e+08, 2.2702e+08, 2.2702e+08, 2.2702e+08,\n",
      "        2.2702e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.6924e+05, 3.6105e+06, 7.2211e+06, 1.4442e+07, 2.8884e+07, 5.7769e+07,\n",
      "        5.7769e+07, 1.1554e+08, 2.3107e+08, 2.3107e+08, 2.3107e+08, 2.3107e+08,\n",
      "        2.3107e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.7221e+05, 3.6739e+06, 7.3478e+06, 1.4696e+07, 2.9391e+07, 5.8782e+07,\n",
      "        5.8782e+07, 1.1756e+08, 2.3513e+08, 2.3513e+08, 2.3513e+08, 2.3513e+08,\n",
      "        2.3513e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.7518e+05, 3.7372e+06, 7.4744e+06, 1.4949e+07, 2.9898e+07, 5.9796e+07,\n",
      "        5.9796e+07, 1.1959e+08, 2.3918e+08, 2.3918e+08, 2.3918e+08, 2.3918e+08,\n",
      "        2.3918e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.7815e+05, 3.8006e+06, 7.6011e+06, 1.5202e+07, 3.0405e+07, 6.0809e+07,\n",
      "        6.0809e+07, 1.2162e+08, 2.4324e+08, 2.4324e+08, 2.4324e+08, 2.4324e+08,\n",
      "        2.4324e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.8112e+05, 3.8639e+06, 7.7278e+06, 1.5456e+07, 3.0911e+07, 6.1823e+07,\n",
      "        6.1823e+07, 1.2365e+08, 2.4729e+08, 2.4729e+08, 2.4729e+08, 2.4729e+08,\n",
      "        2.4729e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.8409e+05, 3.9273e+06, 7.8545e+06, 1.5709e+07, 3.1418e+07, 6.2836e+07,\n",
      "        6.2836e+07, 1.2567e+08, 2.5134e+08, 2.5134e+08, 2.5134e+08, 2.5134e+08,\n",
      "        2.5134e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.8706e+05, 3.9906e+06, 7.9812e+06, 1.5962e+07, 3.1925e+07, 6.3849e+07,\n",
      "        6.3849e+07, 1.2770e+08, 2.5540e+08, 2.5540e+08, 2.5540e+08, 2.5540e+08,\n",
      "        2.5540e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.9003e+05, 4.0539e+06, 8.1079e+06, 1.6216e+07, 3.2431e+07, 6.4863e+07,\n",
      "        6.4863e+07, 1.2973e+08, 2.5945e+08, 2.5945e+08, 2.5945e+08, 2.5945e+08,\n",
      "        2.5945e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.9300e+05, 4.1173e+06, 8.2346e+06, 1.6469e+07, 3.2938e+07, 6.5876e+07,\n",
      "        6.5876e+07, 1.3175e+08, 2.6351e+08, 2.6351e+08, 2.6351e+08, 2.6351e+08,\n",
      "        2.6351e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.9597e+05, 4.1806e+06, 8.3612e+06, 1.6722e+07, 3.3445e+07, 6.6890e+07,\n",
      "        6.6890e+07, 1.3378e+08, 2.6756e+08, 2.6756e+08, 2.6756e+08, 2.6756e+08,\n",
      "        2.6756e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([1.9894e+05, 4.2440e+06, 8.4879e+06, 1.6976e+07, 3.3952e+07, 6.7903e+07,\n",
      "        6.7903e+07, 1.3581e+08, 2.7161e+08, 2.7161e+08, 2.7161e+08, 2.7161e+08,\n",
      "        2.7161e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.0190e+05, 4.3073e+06, 8.6146e+06, 1.7229e+07, 3.4458e+07, 6.8917e+07,\n",
      "        6.8917e+07, 1.3783e+08, 2.7567e+08, 2.7567e+08, 2.7567e+08, 2.7567e+08,\n",
      "        2.7567e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.0487e+05, 4.3706e+06, 8.7413e+06, 1.7483e+07, 3.4965e+07, 6.9930e+07,\n",
      "        6.9930e+07, 1.3986e+08, 2.7972e+08, 2.7972e+08, 2.7972e+08, 2.7972e+08,\n",
      "        2.7972e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.0784e+05, 4.4340e+06, 8.8680e+06, 1.7736e+07, 3.5472e+07, 7.0944e+07,\n",
      "        7.0944e+07, 1.4189e+08, 2.8378e+08, 2.8378e+08, 2.8378e+08, 2.8378e+08,\n",
      "        2.8378e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.1081e+05, 4.4973e+06, 8.9947e+06, 1.7989e+07, 3.5979e+07, 7.1957e+07,\n",
      "        7.1957e+07, 1.4391e+08, 2.8783e+08, 2.8783e+08, 2.8783e+08, 2.8783e+08,\n",
      "        2.8783e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.1378e+05, 4.5607e+06, 9.1214e+06, 1.8243e+07, 3.6485e+07, 7.2971e+07,\n",
      "        7.2971e+07, 1.4594e+08, 2.9188e+08, 2.9188e+08, 2.9188e+08, 2.9188e+08,\n",
      "        2.9188e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.1675e+05, 4.6240e+06, 9.2480e+06, 1.8496e+07, 3.6992e+07, 7.3984e+07,\n",
      "        7.3984e+07, 1.4797e+08, 2.9594e+08, 2.9594e+08, 2.9594e+08, 2.9594e+08,\n",
      "        2.9594e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.1972e+05, 4.6874e+06, 9.3747e+06, 1.8749e+07, 3.7499e+07, 7.4998e+07,\n",
      "        7.4998e+07, 1.5000e+08, 2.9999e+08, 2.9999e+08, 2.9999e+08, 2.9999e+08,\n",
      "        2.9999e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.2269e+05, 4.7507e+06, 9.5014e+06, 1.9003e+07, 3.8006e+07, 7.6011e+07,\n",
      "        7.6011e+07, 1.5202e+08, 3.0405e+08, 3.0405e+08, 3.0405e+08, 3.0405e+08,\n",
      "        3.0405e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.2566e+05, 4.8140e+06, 9.6281e+06, 1.9256e+07, 3.8512e+07, 7.7025e+07,\n",
      "        7.7025e+07, 1.5405e+08, 3.0810e+08, 3.0810e+08, 3.0810e+08, 3.0810e+08,\n",
      "        3.0810e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.2863e+05, 4.8774e+06, 9.7548e+06, 1.9510e+07, 3.9019e+07, 7.8038e+07,\n",
      "        7.8038e+07, 1.5608e+08, 3.1215e+08, 3.1215e+08, 3.1215e+08, 3.1215e+08,\n",
      "        3.1215e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.3160e+05, 4.9407e+06, 9.8815e+06, 1.9763e+07, 3.9526e+07, 7.9052e+07,\n",
      "        7.9052e+07, 1.5810e+08, 3.1621e+08, 3.1621e+08, 3.1621e+08, 3.1621e+08,\n",
      "        3.1621e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.3457e+05, 5.0041e+06, 1.0008e+07, 2.0016e+07, 4.0033e+07, 8.0065e+07,\n",
      "        8.0065e+07, 1.6013e+08, 3.2026e+08, 3.2026e+08, 3.2026e+08, 3.2026e+08,\n",
      "        3.2026e+08], device='cuda:0')\n",
      "loss tensor(10570701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([2.3754e+05, 5.0674e+06, 1.0135e+07, 2.0270e+07, 4.0539e+07, 8.1079e+07,\n",
      "        8.1079e+07, 1.6216e+08, 3.2431e+08, 3.2431e+08, 3.2431e+08, 3.2431e+08,\n",
      "        3.2431e+08], device='cuda:0')\n",
      "====> Epoch: 0 Average loss: 17124.5356\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_log(self, y_hat, y):\n",
    "    a = torch.sum(torch.exp(self.model.logvars) - self.model.logvars - 1)\n",
    "    return  a\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(worker.testloader):\n",
    "    if batch_idx > 1:\n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "inputs, targets = inputs.to(device), targets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0915, -0.0489,  0.0351,  0.0666,  0.0764, -0.1427, -0.0085, -0.0647,\n",
       "          0.1438, -0.1019],\n",
       "        [ 0.0475, -0.0218,  0.0975,  0.0722,  0.0923, -0.0233, -0.1336, -0.0322,\n",
       "          0.1283, -0.0855],\n",
       "        [ 0.0719, -0.1015, -0.0950,  0.1382, -0.0017, -0.0800,  0.0135, -0.1323,\n",
       "          0.1217,  0.0301],\n",
       "        [-0.0173,  0.0359,  0.0961,  0.1381, -0.1089, -0.1463,  0.0335,  0.0634,\n",
       "          0.1047, -0.0094]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_hat = worker.model(inputs)\n",
    "targets_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.3377, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = test_log(worker, targets_hat, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker.model.logvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(1., device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker.model.features[1].logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8736e-13, device='cuda:0')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker.model.features[5].logvar.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in worker.model.parameters():\n",
    "    if param.grad is not None:\n",
    "        print(param.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fisher_information(self, x, y):\n",
    "        '''Estimate the Fisher information of the trainable parameters.\n",
    "        Args:\n",
    "            x: Some input samples.\n",
    "            y: Some class labels.\n",
    "        Returns:\n",
    "            Returns the fisher information of the trainable parameters.\n",
    "            The values are arranged similarly to `EwcEstimator.params()`.\n",
    "        '''\n",
    "        self.eval()\n",
    "        h = self(x)\n",
    "        l = F.log_softmax(h, dim=1)[range(y.size(0)), y]  # log-likelihood of true class\n",
    "        l = l.sum()\n",
    "        l.backward()\n",
    "        grads = [p.grad.data.clone() for p in next(vgg_model.parameters())]\n",
    "        #fisher = [(g ** 2) / len(x) for g in grads]\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(vgg_model.parameters())[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = vgg_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = F.log_softmax(h, dim=1)[range(targets.size(0)), targets]\n",
    "l = l.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(vgg_model.parameters())[0][0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-ddfc51a89889>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfisher_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-131-81817b7b40d6>\u001b[0m in \u001b[0;36mfisher_information\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m#fisher = [(g ** 2) / len(x) for g in grads]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-131-81817b7b40d6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m#fisher = [(g ** 2) / len(x) for g in grads]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "grads = fisher_information(vgg_model, inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object fisher_information.<locals>.<genexpr> at 0x7f3f9003ad00>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.0100]], device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.features[1].logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0121,  0.1512, -0.0713,  0.0835, -0.0545,  0.0224, -0.0582,  0.0532,\n",
       "          0.0411,  0.2262],\n",
       "        [ 0.0982,  0.0749,  0.0089,  0.1046,  0.0789, -0.0737, -0.0137,  0.1690,\n",
       "         -0.1287, -0.0296],\n",
       "        [ 0.0516,  0.0982,  0.0602,  0.1833, -0.0817,  0.1022,  0.0923,  0.1486,\n",
       "         -0.0147,  0.0761],\n",
       "        [-0.0573, -0.0073,  0.0868,  0.2082,  0.0495, -0.0235,  0.0849,  0.1598,\n",
       "         -0.0837, -0.0273]], device='cuda:1', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0486,  0.0086, -0.0676,  0.1767, -0.1206, -0.2048,  0.0473,  0.0801,\n",
       "         -0.0410,  0.0811],\n",
       "        [-0.1244,  0.1539, -0.0604,  0.1329, -0.0943,  0.0711, -0.0596,  0.0191,\n",
       "         -0.0100,  0.0709],\n",
       "        [-0.0457,  0.0104,  0.1206,  0.1887, -0.1184,  0.1160,  0.0257, -0.0554,\n",
       "         -0.1523,  0.0081],\n",
       "        [ 0.0287,  0.0980,  0.0581,  0.2803, -0.2386,  0.0237, -0.0017,  0.0113,\n",
       "         -0.1176, -0.0629]], device='cuda:1', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
